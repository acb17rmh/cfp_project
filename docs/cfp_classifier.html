<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>cfp_classifier API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cfp_classifier</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.utils import shuffle
import pickle
import joblib
import time


class CFPClassifier():

    def __init__(self, corpus, dump_model=False, model_name=&#34;trained_model.sav&#34;, vectorizer_name=&#34;vectorizer.sav&#34;):
        &#34;&#34;&#34;
        Function to load a labelled dataset from a CSV file, and split it into a training set and a testing set.

        Args:
            corpus: the CSV file corpus upon which the classifier will be trained against.
            dump_model: boolean value, if set to True, the classifier will be dumped as .sav files.
            model_name: if dump_model is set to true, the model will be saved with this parameter as a filename.
            vectorizer_name: if dump_model is set to true, the vectorizer will be saved with this parameter as a filename.
        Returns:
            CFPClassifier: an instance of a CFPClassifier object
        &#34;&#34;&#34;
        self.data_train, self.data_test = self.load_data(corpus)
        self.train_counts, self.test_counts = self.vectorize()
        self.vectorizer
        self.dump_model = dump_model
        self.model_name = model_name
        self.vectorizer_name = vectorizer_name
        self.classifier = self.train_classifier(dump_model)

    def load_data(self, data, test_size=0.3):
        &#34;&#34;&#34;
        Function to load a labelled dataset from a CSV file, and split it into a training set and a testing set.

        Args:
            data: the CSV file to be loaded
            test_size: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.
                       If int, represents the absolute number of test samples.
                       If None, the value is set to the complement of the train size.
                       If train_size is also None, it will be set to 0.25.
        Returns:
            (DataFrame, DataFrame): a tuple of Pandas DataFrames, where the first DataFrame is the training data,
                                    and the second DataFrame is the training data.
        &#34;&#34;&#34;
        dataframe = shuffle(pd.read_csv(data, encoding=&#34;latin-1&#34;).fillna(&#34; &#34;))
        new_df = dataframe[[&#39;text&#39;, &#39;class&#39;]].copy()
        new_df.to_html(&#34;results/new_df.html&#34;)
        data_train, data_test = train_test_split(new_df, test_size=test_size)
        return data_train, data_test

    def vectorize(self):
        &#34;&#34;&#34;
        Function to train the classifier on the data provided.

        Returns:
            (sparse matrix, sparse matrix): a tuple of sparse matrices, where the first matrix is the document-term
                                            matrix for the training data, and the second matrix is the document-term
                                            matrix for the testing data.
        &#34;&#34;&#34;
        vectorizer = CountVectorizer(analyzer=preprocess_text)
        self.vectorizer = vectorizer
        train_counts = vectorizer.fit_transform(self.data_train[&#39;text&#39;])
        test_counts = vectorizer.transform(self.data_test[&#39;text&#39;])
        return train_counts, test_counts

    def train_classifier(self, dump_model=False, model_name=&#34;trained_model.sav&#34;, vectorizer_name=&#34;vectorizer.sav&#34;):
        &#34;&#34;&#34;
        Function to train the classifier on the data provided.

        Args:
            dump_model: if set to True, will dump the trained classifier and vectorizer as .sav files.
            model_name: if dump_model is set to true, the model will be saved with this parameter as a filename.
            vectorizer_name: if dump_model is set to true, the vectorizer will be saved with this parameter as a filename.
        Returns:
            MultinomialNB: a trained instance of an sklearn MultinomialNB object.
        &#34;&#34;&#34;
        classifier = MultinomialNB()
        targets = self.data_train[&#34;class&#34;]
        classifier.fit(self.train_counts, targets)
        if self.dump_model:
            joblib.dump(self.vectorizer, self.vectorizer_name)
            joblib.dump(classifier, self.model_name)
        return classifier

    def classify_text(self, input_text_list):
        &#34;&#34;&#34;
        Function to classify a set of input sets.

        Args:
            input_text_list: a list of strings to be classified.
        Returns:
            list: a list of predicted labels corresponding to the input list&#39;s elements.
        &#34;&#34;&#34;
        input_counts = self.vectorizer.transform(input_text_list)
        predictions = self.classifier.predict(input_counts)
        return predictions

    def evaluate(self, model_path=None, vectorizer_path=None):
        &#34;&#34;&#34;
        Function to run the trained classifier on the test set of data and evaluate its performance.
        Also exports the results of the evaluation to an HTML document, which is saved in the /results subfolder.

        Args:
            model_path: if you want to use a dumped model, set this parameter to that model&#39;s file path
            model_path: if you want to use a dumped vectorizer, set this parameter to that vectorizer&#39;s file path
        &#34;&#34;&#34;
        # Run the classifier on test set and report performance
        test_counts, test_set = self.test_counts, self.data_test
        if model_path:
            print (&#34;Using trained model &#39;{}&#39; and vectorizer &#39;{}&#39;&#34;.format(model_path, vectorizer_path))
            loaded_model = joblib.load(model_path)
            loaded_vectorizer = joblib.load(vectorizer_path)
            test_counts = loaded_vectorizer.transform(self.data_test[&#39;text&#39;])
            predictions = loaded_model.predict(test_counts)
        else:
            predictions = self.classifier.predict(test_counts)
        print(classification_report(test_set[&#34;class&#34;], predictions, digits=6))
        print(&#34;ACCURACY: {:.2%}&#34;.format(accuracy_score(test_set[&#34;class&#34;], predictions)))

        # Add the new labels to the DataFrame and save as an HTML document
        predictions_df = pd.DataFrame(predictions)
        test_set[&#34;prediction&#34;] = predictions_df.values
        filename = &#34;results/classifier_results{}.html&#34;.format(time.time())
        test_set.to_html(filename)
        print(&#34;Saved results to file {}&#34;.format(filename))

        # plot confusion matrix as heatmap
        conf = confusion_matrix(predictions, test_set[&#34;class&#34;])
        print(conf)

        # 10-fold cross validation score
        cross_validation_scores = cross_val_score(self.classifier, test_counts, test_set[&#39;class&#39;], cv=10)
        print(cross_validation_scores.mean())

    &#34;&#34;&#34;
    def scatter_plot(self):
        svd = TruncatedSVD(n_components=2).fit(self.train_counts)
        data2D = svd.transform(self.train_counts)
        plt.scatter(data2D[:, 0], data2D[:, 1])
        plt.show()
    &#34;&#34;&#34;

def preprocess_text(text):
    &#34;&#34;&#34;
    Function to preprocess input texts before being vectorized. Performs tokenisation and stopword removal,
    and removes punctuation from the text.

    Args:
        text: the input text to be preprocessed
    Returns:
        list: a list of words in the text
    &#34;&#34;&#34;
    # get the stoplist from the NLTK corpus
    stoplist = (stopwords.words(&#34;english&#34;))
    # uses NLTK to tokenise the input email
    text = word_tokenize(text)
    # removes any punctuation or words if they are in the stoplist
    text_words = [word for word in text if word not in stoplist and word not in string.punctuation]
    return text_words

if __name__ == &#34;__main__&#34;:
    cfp_classifier = CFPClassifier(&#34;data/corpus.csv&#34;)
    cfp_classifier.evaluate()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cfp_classifier.preprocess_text"><code class="name flex">
<span>def <span class="ident">preprocess_text</span></span>(<span>text)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to preprocess input texts before being vectorized. Performs tokenisation and stopword removal,
and removes punctuation from the text.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>text</code></strong></dt>
<dd>the input text to be preprocessed</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>a list of words in the text</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_text(text):
    &#34;&#34;&#34;
    Function to preprocess input texts before being vectorized. Performs tokenisation and stopword removal,
    and removes punctuation from the text.

    Args:
        text: the input text to be preprocessed
    Returns:
        list: a list of words in the text
    &#34;&#34;&#34;
    # get the stoplist from the NLTK corpus
    stoplist = (stopwords.words(&#34;english&#34;))
    # uses NLTK to tokenise the input email
    text = word_tokenize(text)
    # removes any punctuation or words if they are in the stoplist
    text_words = [word for word in text if word not in stoplist and word not in string.punctuation]
    return text_words</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cfp_classifier.CFPClassifier"><code class="flex name class">
<span>class <span class="ident">CFPClassifier</span></span>
<span>(</span><span>corpus, dump_model=False, model_name='trained_model.sav', vectorizer_name='vectorizer.sav')</span>
</code></dt>
<dd>
<section class="desc"><p>Function to load a labelled dataset from a CSV file, and split it into a training set and a testing set.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>corpus</code></strong></dt>
<dd>the CSV file corpus upon which the classifier will be trained against.</dd>
<dt><strong><code>dump_model</code></strong></dt>
<dd>boolean value, if set to True, the classifier will be dumped as .sav files.</dd>
<dt><strong><code>model_name</code></strong></dt>
<dd>if dump_model is set to true, the model will be saved with this parameter as a filename.</dd>
<dt><strong><code>vectorizer_name</code></strong></dt>
<dd>if dump_model is set to true, the vectorizer will be saved with this parameter as a filename.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="cfp_classifier.CFPClassifier" href="#cfp_classifier.CFPClassifier"><code>CFPClassifier</code></a></strong></dt>
<dd>an instance of a CFPClassifier object</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CFPClassifier():

    def __init__(self, corpus, dump_model=False, model_name=&#34;trained_model.sav&#34;, vectorizer_name=&#34;vectorizer.sav&#34;):
        &#34;&#34;&#34;
        Function to load a labelled dataset from a CSV file, and split it into a training set and a testing set.

        Args:
            corpus: the CSV file corpus upon which the classifier will be trained against.
            dump_model: boolean value, if set to True, the classifier will be dumped as .sav files.
            model_name: if dump_model is set to true, the model will be saved with this parameter as a filename.
            vectorizer_name: if dump_model is set to true, the vectorizer will be saved with this parameter as a filename.
        Returns:
            CFPClassifier: an instance of a CFPClassifier object
        &#34;&#34;&#34;
        self.data_train, self.data_test = self.load_data(corpus)
        self.train_counts, self.test_counts = self.vectorize()
        self.vectorizer
        self.dump_model = dump_model
        self.model_name = model_name
        self.vectorizer_name = vectorizer_name
        self.classifier = self.train_classifier(dump_model)

    def load_data(self, data, test_size=0.3):
        &#34;&#34;&#34;
        Function to load a labelled dataset from a CSV file, and split it into a training set and a testing set.

        Args:
            data: the CSV file to be loaded
            test_size: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.
                       If int, represents the absolute number of test samples.
                       If None, the value is set to the complement of the train size.
                       If train_size is also None, it will be set to 0.25.
        Returns:
            (DataFrame, DataFrame): a tuple of Pandas DataFrames, where the first DataFrame is the training data,
                                    and the second DataFrame is the training data.
        &#34;&#34;&#34;
        dataframe = shuffle(pd.read_csv(data, encoding=&#34;latin-1&#34;).fillna(&#34; &#34;))
        new_df = dataframe[[&#39;text&#39;, &#39;class&#39;]].copy()
        new_df.to_html(&#34;results/new_df.html&#34;)
        data_train, data_test = train_test_split(new_df, test_size=test_size)
        return data_train, data_test

    def vectorize(self):
        &#34;&#34;&#34;
        Function to train the classifier on the data provided.

        Returns:
            (sparse matrix, sparse matrix): a tuple of sparse matrices, where the first matrix is the document-term
                                            matrix for the training data, and the second matrix is the document-term
                                            matrix for the testing data.
        &#34;&#34;&#34;
        vectorizer = CountVectorizer(analyzer=preprocess_text)
        self.vectorizer = vectorizer
        train_counts = vectorizer.fit_transform(self.data_train[&#39;text&#39;])
        test_counts = vectorizer.transform(self.data_test[&#39;text&#39;])
        return train_counts, test_counts

    def train_classifier(self, dump_model=False, model_name=&#34;trained_model.sav&#34;, vectorizer_name=&#34;vectorizer.sav&#34;):
        &#34;&#34;&#34;
        Function to train the classifier on the data provided.

        Args:
            dump_model: if set to True, will dump the trained classifier and vectorizer as .sav files.
            model_name: if dump_model is set to true, the model will be saved with this parameter as a filename.
            vectorizer_name: if dump_model is set to true, the vectorizer will be saved with this parameter as a filename.
        Returns:
            MultinomialNB: a trained instance of an sklearn MultinomialNB object.
        &#34;&#34;&#34;
        classifier = MultinomialNB()
        targets = self.data_train[&#34;class&#34;]
        classifier.fit(self.train_counts, targets)
        if self.dump_model:
            joblib.dump(self.vectorizer, self.vectorizer_name)
            joblib.dump(classifier, self.model_name)
        return classifier

    def classify_text(self, input_text_list):
        &#34;&#34;&#34;
        Function to classify a set of input sets.

        Args:
            input_text_list: a list of strings to be classified.
        Returns:
            list: a list of predicted labels corresponding to the input list&#39;s elements.
        &#34;&#34;&#34;
        input_counts = self.vectorizer.transform(input_text_list)
        predictions = self.classifier.predict(input_counts)
        return predictions

    def evaluate(self, model_path=None, vectorizer_path=None):
        &#34;&#34;&#34;
        Function to run the trained classifier on the test set of data and evaluate its performance.
        Also exports the results of the evaluation to an HTML document, which is saved in the /results subfolder.

        Args:
            model_path: if you want to use a dumped model, set this parameter to that model&#39;s file path
            model_path: if you want to use a dumped vectorizer, set this parameter to that vectorizer&#39;s file path
        &#34;&#34;&#34;
        # Run the classifier on test set and report performance
        test_counts, test_set = self.test_counts, self.data_test
        if model_path:
            print (&#34;Using trained model &#39;{}&#39; and vectorizer &#39;{}&#39;&#34;.format(model_path, vectorizer_path))
            loaded_model = joblib.load(model_path)
            loaded_vectorizer = joblib.load(vectorizer_path)
            test_counts = loaded_vectorizer.transform(self.data_test[&#39;text&#39;])
            predictions = loaded_model.predict(test_counts)
        else:
            predictions = self.classifier.predict(test_counts)
        print(classification_report(test_set[&#34;class&#34;], predictions, digits=6))
        print(&#34;ACCURACY: {:.2%}&#34;.format(accuracy_score(test_set[&#34;class&#34;], predictions)))

        # Add the new labels to the DataFrame and save as an HTML document
        predictions_df = pd.DataFrame(predictions)
        test_set[&#34;prediction&#34;] = predictions_df.values
        filename = &#34;results/classifier_results{}.html&#34;.format(time.time())
        test_set.to_html(filename)
        print(&#34;Saved results to file {}&#34;.format(filename))

        # plot confusion matrix as heatmap
        conf = confusion_matrix(predictions, test_set[&#34;class&#34;])
        print(conf)

        # 10-fold cross validation score
        cross_validation_scores = cross_val_score(self.classifier, test_counts, test_set[&#39;class&#39;], cv=10)
        print(cross_validation_scores.mean())

    &#34;&#34;&#34;
    def scatter_plot(self):
        svd = TruncatedSVD(n_components=2).fit(self.train_counts)
        data2D = svd.transform(self.train_counts)
        plt.scatter(data2D[:, 0], data2D[:, 1])
        plt.show()
    &#34;&#34;&#34;</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="cfp_classifier.CFPClassifier.classify_text"><code class="name flex">
<span>def <span class="ident">classify_text</span></span>(<span>self, input_text_list)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to classify a set of input sets.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_text_list</code></strong></dt>
<dd>a list of strings to be classified.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>a list of predicted labels corresponding to the input list's elements.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def classify_text(self, input_text_list):
    &#34;&#34;&#34;
    Function to classify a set of input sets.

    Args:
        input_text_list: a list of strings to be classified.
    Returns:
        list: a list of predicted labels corresponding to the input list&#39;s elements.
    &#34;&#34;&#34;
    input_counts = self.vectorizer.transform(input_text_list)
    predictions = self.classifier.predict(input_counts)
    return predictions</code></pre>
</details>
</dd>
<dt id="cfp_classifier.CFPClassifier.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, model_path=None, vectorizer_path=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to run the trained classifier on the test set of data and evaluate its performance.
Also exports the results of the evaluation to an HTML document, which is saved in the /results subfolder.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_path</code></strong></dt>
<dd>if you want to use a dumped model, set this parameter to that model's file path</dd>
<dt><strong><code>model_path</code></strong></dt>
<dd>if you want to use a dumped vectorizer, set this parameter to that vectorizer's file path</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, model_path=None, vectorizer_path=None):
    &#34;&#34;&#34;
    Function to run the trained classifier on the test set of data and evaluate its performance.
    Also exports the results of the evaluation to an HTML document, which is saved in the /results subfolder.

    Args:
        model_path: if you want to use a dumped model, set this parameter to that model&#39;s file path
        model_path: if you want to use a dumped vectorizer, set this parameter to that vectorizer&#39;s file path
    &#34;&#34;&#34;
    # Run the classifier on test set and report performance
    test_counts, test_set = self.test_counts, self.data_test
    if model_path:
        print (&#34;Using trained model &#39;{}&#39; and vectorizer &#39;{}&#39;&#34;.format(model_path, vectorizer_path))
        loaded_model = joblib.load(model_path)
        loaded_vectorizer = joblib.load(vectorizer_path)
        test_counts = loaded_vectorizer.transform(self.data_test[&#39;text&#39;])
        predictions = loaded_model.predict(test_counts)
    else:
        predictions = self.classifier.predict(test_counts)
    print(classification_report(test_set[&#34;class&#34;], predictions, digits=6))
    print(&#34;ACCURACY: {:.2%}&#34;.format(accuracy_score(test_set[&#34;class&#34;], predictions)))

    # Add the new labels to the DataFrame and save as an HTML document
    predictions_df = pd.DataFrame(predictions)
    test_set[&#34;prediction&#34;] = predictions_df.values
    filename = &#34;results/classifier_results{}.html&#34;.format(time.time())
    test_set.to_html(filename)
    print(&#34;Saved results to file {}&#34;.format(filename))

    # plot confusion matrix as heatmap
    conf = confusion_matrix(predictions, test_set[&#34;class&#34;])
    print(conf)

    # 10-fold cross validation score
    cross_validation_scores = cross_val_score(self.classifier, test_counts, test_set[&#39;class&#39;], cv=10)
    print(cross_validation_scores.mean())</code></pre>
</details>
</dd>
<dt id="cfp_classifier.CFPClassifier.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>self, data, test_size=0.3)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to load a labelled dataset from a CSV file, and split it into a training set and a testing set.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong></dt>
<dd>the CSV file to be loaded</dd>
<dt><strong><code>test_size</code></strong></dt>
<dd>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.
If int, represents the absolute number of test samples.
If None, the value is set to the complement of the train size.
If train_size is also None, it will be set to 0.25.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(DataFrame, DataFrame): a tuple of Pandas DataFrames, where the first DataFrame is the training data,
and the second DataFrame is the training data.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(self, data, test_size=0.3):
    &#34;&#34;&#34;
    Function to load a labelled dataset from a CSV file, and split it into a training set and a testing set.

    Args:
        data: the CSV file to be loaded
        test_size: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.
                   If int, represents the absolute number of test samples.
                   If None, the value is set to the complement of the train size.
                   If train_size is also None, it will be set to 0.25.
    Returns:
        (DataFrame, DataFrame): a tuple of Pandas DataFrames, where the first DataFrame is the training data,
                                and the second DataFrame is the training data.
    &#34;&#34;&#34;
    dataframe = shuffle(pd.read_csv(data, encoding=&#34;latin-1&#34;).fillna(&#34; &#34;))
    new_df = dataframe[[&#39;text&#39;, &#39;class&#39;]].copy()
    new_df.to_html(&#34;results/new_df.html&#34;)
    data_train, data_test = train_test_split(new_df, test_size=test_size)
    return data_train, data_test</code></pre>
</details>
</dd>
<dt id="cfp_classifier.CFPClassifier.train_classifier"><code class="name flex">
<span>def <span class="ident">train_classifier</span></span>(<span>self, dump_model=False, model_name='trained_model.sav', vectorizer_name='vectorizer.sav')</span>
</code></dt>
<dd>
<section class="desc"><p>Function to train the classifier on the data provided.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dump_model</code></strong></dt>
<dd>if set to True, will dump the trained classifier and vectorizer as .sav files.</dd>
<dt><strong><code>model_name</code></strong></dt>
<dd>if dump_model is set to true, the model will be saved with this parameter as a filename.</dd>
<dt><strong><code>vectorizer_name</code></strong></dt>
<dd>if dump_model is set to true, the vectorizer will be saved with this parameter as a filename.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>MultinomialNB</code></strong></dt>
<dd>a trained instance of an sklearn MultinomialNB object.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_classifier(self, dump_model=False, model_name=&#34;trained_model.sav&#34;, vectorizer_name=&#34;vectorizer.sav&#34;):
    &#34;&#34;&#34;
    Function to train the classifier on the data provided.

    Args:
        dump_model: if set to True, will dump the trained classifier and vectorizer as .sav files.
        model_name: if dump_model is set to true, the model will be saved with this parameter as a filename.
        vectorizer_name: if dump_model is set to true, the vectorizer will be saved with this parameter as a filename.
    Returns:
        MultinomialNB: a trained instance of an sklearn MultinomialNB object.
    &#34;&#34;&#34;
    classifier = MultinomialNB()
    targets = self.data_train[&#34;class&#34;]
    classifier.fit(self.train_counts, targets)
    if self.dump_model:
        joblib.dump(self.vectorizer, self.vectorizer_name)
        joblib.dump(classifier, self.model_name)
    return classifier</code></pre>
</details>
</dd>
<dt id="cfp_classifier.CFPClassifier.vectorize"><code class="name flex">
<span>def <span class="ident">vectorize</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to train the classifier on the data provided.</p>
<h2 id="returns">Returns</h2>
<p>(sparse matrix, sparse matrix): a tuple of sparse matrices, where the first matrix is the document-term
matrix for the training data, and the second matrix is the document-term
matrix for the testing data.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vectorize(self):
    &#34;&#34;&#34;
    Function to train the classifier on the data provided.

    Returns:
        (sparse matrix, sparse matrix): a tuple of sparse matrices, where the first matrix is the document-term
                                        matrix for the training data, and the second matrix is the document-term
                                        matrix for the testing data.
    &#34;&#34;&#34;
    vectorizer = CountVectorizer(analyzer=preprocess_text)
    self.vectorizer = vectorizer
    train_counts = vectorizer.fit_transform(self.data_train[&#39;text&#39;])
    test_counts = vectorizer.transform(self.data_test[&#39;text&#39;])
    return train_counts, test_counts</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
    <li><code><a title="cfp_classifier" href="cfp_classifier.html">cfp_classifier</a></code></li>
    <li><code><a title="extract" href="extract.html">extract</a></code></li>
    <li><code><a title="evaluate" href="evaluate.html">evaluate</a></code></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cfp_classifier.preprocess_text" href="#cfp_classifier.preprocess_text">preprocess_text</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cfp_classifier.CFPClassifier" href="#cfp_classifier.CFPClassifier">CFPClassifier</a></code></h4>
<ul class="">
<li><code><a title="cfp_classifier.CFPClassifier.classify_text" href="#cfp_classifier.CFPClassifier.classify_text">classify_text</a></code></li>
<li><code><a title="cfp_classifier.CFPClassifier.evaluate" href="#cfp_classifier.CFPClassifier.evaluate">evaluate</a></code></li>
<li><code><a title="cfp_classifier.CFPClassifier.load_data" href="#cfp_classifier.CFPClassifier.load_data">load_data</a></code></li>
<li><code><a title="cfp_classifier.CFPClassifier.train_classifier" href="#cfp_classifier.CFPClassifier.train_classifier">train_classifier</a></code></li>
<li><code><a title="cfp_classifier.CFPClassifier.vectorize" href="#cfp_classifier.CFPClassifier.vectorize">vectorize</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>