<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>extract API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>extract</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import dateparser
import pandas
import re
import spacy
import argparse
import os.path

# Handles loading in files via command line arguments
def is_valid_file(parser, arg):
    &#34;&#34;&#34;
    Given a file path, checks that the file exists.
    Args:
        arg: the path to the file
    Returns:
          str: the file path as a string (if the file does exist)
          error: an error (if the file does not exist)
    &#34;&#34;&#34;
    if not os.path.isfile(arg):
        parser.error(&#34;ERROR: file %s does not exist.&#34; % arg) # if no file throw error
    else:
        return arg  # else return file path

def extract_locations(doc):
    &#34;&#34;&#34;
    Extracts the first location mentioned in the CFP&#39;s text
    Args:
        doc: a spaCy document
    Returns:
        location: the first location mentioned in the text
    &#34;&#34;&#34;

    # Initialise lists for the locations within a given CFP
    cfp_locations = []

    for entity in doc.ents:
        if entity.label_ == &#34;GPE&#34;:
            return entity.text

    return None

def extract_conference_name(split_cfp_text):

    &#34;&#34;&#34;
    Function to extract the conference name from a CFP text. Uses rule-based patterns to assign scores to substrings
    of the CFP&#39;s text, and returns the one with the highest score. Takes regex patterns containing key words to filter
    by as parameters. By default, these regexes will match any string.
    Args:
        split_cfp_text: A list containing strings, where each string is a sentence in the original text.
    Returns:
        str: The highest ranking string in the text.
    &#34;&#34;&#34;
    # a dictionary of form (sentence -&gt; score)
    candidate_names = {}
    counter = 0

    conference_name_regex = re.compile(
        &#34;|&#34;.join([&#34;workshop&#34;, &#34;conference&#34;, &#34;meeting&#34;, &#34;theme&#34;, &#34;international&#34;, &#34;symposium&#34;, &#34;forum&#34;]))
    ordinal_regex = re.compile(
        &#34;|&#34;.join([&#34;first&#34;, &#34;second&#34;, &#34;third&#34;, &#34;fourth&#34;, &#34;fifth&#34;, &#34;sixth&#34;, &#34;seventh&#34;, &#34;eighth&#34;, &#34;nineth&#34;,
                  &#34;1st&#34;, &#34;2nd&#34;, &#34;3rd&#34;, &#34;4th&#34;, &#34;5th&#34;, &#34;6th&#34;, &#34;7th&#34;, &#34;8th&#34;, &#34;9th&#34;]), re.IGNORECASE)
    conjunction_regex = re.compile(&#34;|&#34;.join([&#34;conjunction&#34;, &#34;assosciate&#34;, &#34;joint&#34;, &#34;located&#34;]), re.IGNORECASE)
    url_regex = re.compile(
        r&#34;&#34;&#34;(?i)\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\s()&lt;&gt;{}\[\]]+|\([^\s()]*?\([^\s()]+\)[^\s()]*?\)|\([^\s]+?\))+(?:\([^\s()]*?\([^\s()]+\)[^\s()]*?\)|\([^\s]+?\)|[^\s`!()\[\]{};:&#39;&#34;.,&lt;&gt;?«»“”‘’])|(?:(?&lt;!@)[a-z0-9]+(?:[.\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\b/?(?!@)))&#34;&#34;&#34;)

    for index, sent in enumerate(split_cfp_text):
        score = 0
        sent = sent.strip()
        next_sentence_bonus = False
        if len(sent.split()) &lt; 4 or len(sent.split()) &gt; 20:
            score -= 50
        if counter &lt; 5:
            score += 10 - (2 * counter)
        if next_sentence_bonus:
            score += 10
        if &#34;call for papers&#34; in sent.lower():
            next_sentence_bonus = True
        if sent.endswith(&#34; on&#34;) or sent.endswith(&#34; for&#34;):
           sent += &#34; &#34; + split_cfp_text[index + 1]
        if re.search(conference_name_regex, sent.lower()):
            score += 8
        if re.search(ordinal_regex, sent.lower()) and counter &lt; 10:
            score += 10
        if re.search(conjunction_regex, sent.lower()):
            score -= 5
        if re.search(url_regex, sent.lower()):
            score -= 5

        candidate_names[sent] = score
        counter += 1

    # return the sentence with the highest score
    highest_score = (max(candidate_names, key=candidate_names.get)) if candidate_names else 0

    return highest_score

def preprocess_text(text):
    &#34;&#34;&#34;
    Method to preprocess text for information extraction. Text is split on newlines and commas,
    and any conference names split over 2 lines are merged into one.
    Args:
        split_cfp_text: A list containing strings, where each string is a sentence in the original text.
    Returns:
        list: a list of preprocessed sentences.
    &#34;&#34;&#34;

    text = text.replace(&#39;. &#39;, &#39;\n&#39;)
    text = text.splitlines()
    text = [substring for substring in text if substring is not &#34;&#34;]
    return text

def extract_dates(split_cfp_text):
    &#34;&#34;&#34;
    Function which extracts mentions of dates from the CFP&#39;s text.
    Args:
        split_cfp_text: A list containing strings, where each string is a sentence in the original text.
    Returns:
        dict: A dictionary of form {date -&gt; sentence containing that date}.
    &#34;&#34;&#34;
    # a dictionary mapping a date to the sentence it is in
    date_to_sentence = {}

    for sentence_doc in nlp.pipe(split_cfp_text, batch_size=len(split_cfp_text), disable=[&#34;tagger&#34;, &#34;parser&#34;]):
        for entity in sentence_doc.ents:
            if entity.label_ == &#34;DATE&#34; and len(entity.text) &gt;= 6:
                date = entity.text
                date_to_sentence[date] = sentence_doc.text[:]

        # removes any dates that cannot be parsed, i.e are incomplete, and makes sentence lowercase for next step
    date_to_sentence = {date: sent.lower() for date, sent in date_to_sentence.items() if
                        dateparser.parse(date) is not None}
    # returns a dictionary of form (date -&gt; sentence)
    return date_to_sentence

def get_start_date(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the start date of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        conference_start: The date the conference starts, as a String.
    &#34;&#34;&#34;
    conference_start = None

    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(CONFERENCE_DATES_REGEX, sentence):
            conference_start = date_object

    # if no date found for start date, then use the first one found
    if conference_start is None:
        conference_start = list(date_to_sentence)[0]
        conference_start = dateparser.parse(conference_start)

    return conference_start

def get_submission_deadline(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the submission deadline of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        submission_deadline: The submission deadline date, as a String.
    &#34;&#34;&#34;
    submission_deadline = None
    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(SUBMISSION_DEADLINE_REGEX, sentence):
            if submission_deadline is None:
                submission_deadline = date_object
    return submission_deadline

def get_notification_due(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the submission deadline of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        notification_due: The notification due date, as a String.
    &#34;&#34;&#34;
    notification_due = None
    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(NOTIFICATION_DEADLINE_REGEX, sentence):
            if notification_due is None:
                notification_due = date_object
    return notification_due

def get_final_version_deadline(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the submission deadline of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        final_version_deadline: The final version deadline date, as a String.
    &#34;&#34;&#34;
    final_version_deadline = None
    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(FINAL_VERSION_DEADLINE_REGEX, sentence):
            if final_version_deadline is None:
                final_version_deadline = date_object
    return final_version_deadline

if __name__ == &#34;__main__&#34;:
    # Load CFP data and convert dates from strings into Datetime objects
    dataframe = pandas.read_csv(args.input_file, encoding=&#34;latin-1&#34;,
                                usecols=[&#34;text&#34;, &#34;location&#34;, &#34;name&#34;, &#34;start_date&#34;, &#34;submission_deadline&#34;,
                                         &#34;notification_due&#34;, &#34;final_version_deadline&#34;])

    nlp = spacy.load(&#39;en_core_web_sm&#39;, disable=[&#39;tagger&#39;, &#39;parser&#39;, &#39;textcat&#39;])
    documents = []
    for doc in nlp.pipe(dataframe[&#39;text&#39;]):
        documents.append(doc)


    # Regex patterns for identifying which date is which
    CONFERENCE_DATES_REGEX = re.compile(&#34;|&#34;.join([&#34;when&#34;, &#34;workshop&#34;, &#34;held&#34;, &#34;conference&#34;, &#34;held&#34;]))
    SUBMISSION_DEADLINE_REGEX = re.compile(&#34;|&#34;.join([&#34;submit&#34;, &#34;submission&#34;, &#34;paper&#34;, &#34;due&#34;, &#34;deadline&#34;]))
    FINAL_VERSION_DEADLINE_REGEX = re.compile(
        &#34;|&#34;.join([&#34;final&#34;, &#34;camera&#34;, &#34;ready&#34;, &#34;camera-ready&#34;, &#34;last&#34;, &#34;manuscript&#34;]))
    NOTIFICATION_DEADLINE_REGEX = re.compile(
        &#34;|&#34;.join([&#34;notice&#34;, &#34;notices&#34;, &#34;notified&#34;, &#34;notification&#34;, &#34;notifications&#34;, &#34;acceptance&#34;]))
    CONFERENCE_NAME_REGEX = re.compile(
        &#34;|&#34;.join([&#34;workshop&#34;, &#34;conference&#34;, &#34;meeting&#34;, &#34;theme&#34;, &#34;international&#34;, &#34;symposium&#34;, &#34;forum&#34;]))
    ORDINAL_REGEX = re.compile(
        &#34;|&#34;.join([&#34;first&#34;, &#34;second&#34;, &#34;third&#34;, &#34;fourth&#34;, &#34;fifth&#34;, &#34;sixth&#34;, &#34;seventh&#34;, &#34;eighth&#34;, &#34;nineth&#34;,
                  &#34;1st&#34;, &#34;2nd&#34;, &#34;3rd&#34;, &#34;4th&#34;, &#34;5th&#34;, &#34;6th&#34;, &#34;7th&#34;, &#34;8th&#34;, &#34;9th&#34;]), re.IGNORECASE)
    CONJUNCTION_REGEX = re.compile(&#34;|&#34;.join([&#34;conjunction&#34;, &#34;assosciate&#34;, &#34;joint&#34;, &#34;located&#34;]), re.IGNORECASE)
    WEB_URL_REGEX = re.compile(
        r&#34;&#34;&#34;(?i)\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\s()&lt;&gt;{}\[\]]+|\([^\s()]*?\([^\s()]+\)[^\s()]*?\)|\([^\s]+?\))+(?:\([^\s()]*?\([^\s()]+\)[^\s()]*?\)|\([^\s]+?\)|[^\s`!()\[\]{};:&#39;&#34;.,&lt;&gt;?«»“”‘’])|(?:(?&lt;!@)[a-z0-9]+(?:[.\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\b/?(?!@)))&#34;&#34;&#34;)

    dataframe[&#39;document&#39;] = documents
    dataframe[&#39;detected_location&#39;] = dataframe[&#39;document&#39;].apply(extract_locations)
    dataframe[&#39;split_cfp_text&#39;] = dataframe[&#39;text&#39;].apply(preprocess_text)
    dataframe[&#39;detected_conference_name&#39;] = dataframe[&#39;split_cfp_text&#39;].apply(extract_conference_name)
    dataframe[&#39;date_to_sentence&#39;] = dataframe[&#39;split_cfp_text&#39;].apply(extract_dates)
    dataframe[&#39;detected_start_date&#39;] = dataframe[&#39;date_to_sentence&#39;].apply(get_start_date)
    dataframe[&#39;detected_submission_deadline&#39;] = dataframe[&#39;date_to_sentence&#39;].apply(get_submission_deadline)
    dataframe[&#39;detected_notification_due&#39;] = dataframe[&#39;date_to_sentence&#39;].apply(get_notification_due)
    dataframe[&#39;detected_final_version_deadline&#39;] = dataframe[&#39;date_to_sentence&#39;].apply(get_final_version_deadline)

    dataframe.to_csv(args.output_file, columns=[&#34;name&#34;, &#34;location&#34;, &#34;start_date&#34;, &#34;submission_deadline&#34;, &#34;notification_due&#34;,
                                         &#34;final_version_deadline&#34;, &#34;detected_conference_name&#34;, &#34;detected_location&#34;,
                                         &#34;detected_start_date&#34;, &#34;detected_submission_deadline&#34;, &#34;detected_notification_due&#34;,
                                         &#34;detected_final_version_deadline&#34;], date_format=&#39;%d/%m/%Y&#39;)
    print (&#34;Extracted data saved to {}&#34;.format(args.output_file))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="extract.extract_conference_name"><code class="name flex">
<span>def <span class="ident">extract_conference_name</span></span>(<span>split_cfp_text)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to extract the conference name from a CFP text. Uses rule-based patterns to assign scores to substrings
of the CFP's text, and returns the one with the highest score. Takes regex patterns containing key words to filter
by as parameters. By default, these regexes will match any string.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>split_cfp_text</code></strong></dt>
<dd>A list containing strings, where each string is a sentence in the original text.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>The highest ranking string in the text.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_conference_name(split_cfp_text):

    &#34;&#34;&#34;
    Function to extract the conference name from a CFP text. Uses rule-based patterns to assign scores to substrings
    of the CFP&#39;s text, and returns the one with the highest score. Takes regex patterns containing key words to filter
    by as parameters. By default, these regexes will match any string.
    Args:
        split_cfp_text: A list containing strings, where each string is a sentence in the original text.
    Returns:
        str: The highest ranking string in the text.
    &#34;&#34;&#34;
    # a dictionary of form (sentence -&gt; score)
    candidate_names = {}
    counter = 0

    conference_name_regex = re.compile(
        &#34;|&#34;.join([&#34;workshop&#34;, &#34;conference&#34;, &#34;meeting&#34;, &#34;theme&#34;, &#34;international&#34;, &#34;symposium&#34;, &#34;forum&#34;]))
    ordinal_regex = re.compile(
        &#34;|&#34;.join([&#34;first&#34;, &#34;second&#34;, &#34;third&#34;, &#34;fourth&#34;, &#34;fifth&#34;, &#34;sixth&#34;, &#34;seventh&#34;, &#34;eighth&#34;, &#34;nineth&#34;,
                  &#34;1st&#34;, &#34;2nd&#34;, &#34;3rd&#34;, &#34;4th&#34;, &#34;5th&#34;, &#34;6th&#34;, &#34;7th&#34;, &#34;8th&#34;, &#34;9th&#34;]), re.IGNORECASE)
    conjunction_regex = re.compile(&#34;|&#34;.join([&#34;conjunction&#34;, &#34;assosciate&#34;, &#34;joint&#34;, &#34;located&#34;]), re.IGNORECASE)
    url_regex = re.compile(
        r&#34;&#34;&#34;(?i)\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\s()&lt;&gt;{}\[\]]+|\([^\s()]*?\([^\s()]+\)[^\s()]*?\)|\([^\s]+?\))+(?:\([^\s()]*?\([^\s()]+\)[^\s()]*?\)|\([^\s]+?\)|[^\s`!()\[\]{};:&#39;&#34;.,&lt;&gt;?«»“”‘’])|(?:(?&lt;!@)[a-z0-9]+(?:[.\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\b/?(?!@)))&#34;&#34;&#34;)

    for index, sent in enumerate(split_cfp_text):
        score = 0
        sent = sent.strip()
        next_sentence_bonus = False
        if len(sent.split()) &lt; 4 or len(sent.split()) &gt; 20:
            score -= 50
        if counter &lt; 5:
            score += 10 - (2 * counter)
        if next_sentence_bonus:
            score += 10
        if &#34;call for papers&#34; in sent.lower():
            next_sentence_bonus = True
        if sent.endswith(&#34; on&#34;) or sent.endswith(&#34; for&#34;):
           sent += &#34; &#34; + split_cfp_text[index + 1]
        if re.search(conference_name_regex, sent.lower()):
            score += 8
        if re.search(ordinal_regex, sent.lower()) and counter &lt; 10:
            score += 10
        if re.search(conjunction_regex, sent.lower()):
            score -= 5
        if re.search(url_regex, sent.lower()):
            score -= 5

        candidate_names[sent] = score
        counter += 1

    # return the sentence with the highest score
    highest_score = (max(candidate_names, key=candidate_names.get)) if candidate_names else 0

    return highest_score</code></pre>
</details>
</dd>
<dt id="extract.extract_dates"><code class="name flex">
<span>def <span class="ident">extract_dates</span></span>(<span>split_cfp_text)</span>
</code></dt>
<dd>
<section class="desc"><p>Function which extracts mentions of dates from the CFP's text.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>split_cfp_text</code></strong></dt>
<dd>A list containing strings, where each string is a sentence in the original text.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dict</code></strong></dt>
<dd>A dictionary of form {date -&gt; sentence containing that date}.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_dates(split_cfp_text):
    &#34;&#34;&#34;
    Function which extracts mentions of dates from the CFP&#39;s text.
    Args:
        split_cfp_text: A list containing strings, where each string is a sentence in the original text.
    Returns:
        dict: A dictionary of form {date -&gt; sentence containing that date}.
    &#34;&#34;&#34;
    # a dictionary mapping a date to the sentence it is in
    date_to_sentence = {}

    for sentence_doc in nlp.pipe(split_cfp_text, batch_size=len(split_cfp_text), disable=[&#34;tagger&#34;, &#34;parser&#34;]):
        for entity in sentence_doc.ents:
            if entity.label_ == &#34;DATE&#34; and len(entity.text) &gt;= 6:
                date = entity.text
                date_to_sentence[date] = sentence_doc.text[:]

        # removes any dates that cannot be parsed, i.e are incomplete, and makes sentence lowercase for next step
    date_to_sentence = {date: sent.lower() for date, sent in date_to_sentence.items() if
                        dateparser.parse(date) is not None}
    # returns a dictionary of form (date -&gt; sentence)
    return date_to_sentence</code></pre>
</details>
</dd>
<dt id="extract.extract_locations"><code class="name flex">
<span>def <span class="ident">extract_locations</span></span>(<span>doc)</span>
</code></dt>
<dd>
<section class="desc"><p>Extracts the first location mentioned in the CFP's text</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>doc</code></strong></dt>
<dd>a spaCy document</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>location</code></strong></dt>
<dd>the first location mentioned in the text</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_locations(doc):
    &#34;&#34;&#34;
    Extracts the first location mentioned in the CFP&#39;s text
    Args:
        doc: a spaCy document
    Returns:
        location: the first location mentioned in the text
    &#34;&#34;&#34;

    # Initialise lists for the locations within a given CFP
    cfp_locations = []

    for entity in doc.ents:
        if entity.label_ == &#34;GPE&#34;:
            return entity.text

    return None</code></pre>
</details>
</dd>
<dt id="extract.get_final_version_deadline"><code class="name flex">
<span>def <span class="ident">get_final_version_deadline</span></span>(<span>date_to_sentence)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to extract the submission deadline of a conference from a Call for Paper.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>date_to_sentence</code></strong></dt>
<dd>a dictionary mapping each date in the text to the sentence containing it.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>final_version_deadline</code></strong></dt>
<dd>The final version deadline date, as a String.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_final_version_deadline(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the submission deadline of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        final_version_deadline: The final version deadline date, as a String.
    &#34;&#34;&#34;
    final_version_deadline = None
    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(FINAL_VERSION_DEADLINE_REGEX, sentence):
            if final_version_deadline is None:
                final_version_deadline = date_object
    return final_version_deadline</code></pre>
</details>
</dd>
<dt id="extract.get_notification_due"><code class="name flex">
<span>def <span class="ident">get_notification_due</span></span>(<span>date_to_sentence)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to extract the submission deadline of a conference from a Call for Paper.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>date_to_sentence</code></strong></dt>
<dd>a dictionary mapping each date in the text to the sentence containing it.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>notification_due</code></strong></dt>
<dd>The notification due date, as a String.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_notification_due(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the submission deadline of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        notification_due: The notification due date, as a String.
    &#34;&#34;&#34;
    notification_due = None
    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(NOTIFICATION_DEADLINE_REGEX, sentence):
            if notification_due is None:
                notification_due = date_object
    return notification_due</code></pre>
</details>
</dd>
<dt id="extract.get_start_date"><code class="name flex">
<span>def <span class="ident">get_start_date</span></span>(<span>date_to_sentence)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to extract the start date of a conference from a Call for Paper.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>date_to_sentence</code></strong></dt>
<dd>a dictionary mapping each date in the text to the sentence containing it.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>conference_start</code></strong></dt>
<dd>The date the conference starts, as a String.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_start_date(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the start date of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        conference_start: The date the conference starts, as a String.
    &#34;&#34;&#34;
    conference_start = None

    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(CONFERENCE_DATES_REGEX, sentence):
            conference_start = date_object

    # if no date found for start date, then use the first one found
    if conference_start is None:
        conference_start = list(date_to_sentence)[0]
        conference_start = dateparser.parse(conference_start)

    return conference_start</code></pre>
</details>
</dd>
<dt id="extract.get_submission_deadline"><code class="name flex">
<span>def <span class="ident">get_submission_deadline</span></span>(<span>date_to_sentence)</span>
</code></dt>
<dd>
<section class="desc"><p>Function to extract the submission deadline of a conference from a Call for Paper.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>date_to_sentence</code></strong></dt>
<dd>a dictionary mapping each date in the text to the sentence containing it.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>submission_deadline</code></strong></dt>
<dd>The submission deadline date, as a String.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_submission_deadline(date_to_sentence):
    &#34;&#34;&#34;
    Function to extract the submission deadline of a conference from a Call for Paper.
    Args:
        date_to_sentence: a dictionary mapping each date in the text to the sentence containing it.
    Returns:
        submission_deadline: The submission deadline date, as a String.
    &#34;&#34;&#34;
    submission_deadline = None
    for date in date_to_sentence:
        sentence = date_to_sentence[date].lower()
        date_object = dateparser.parse(date)

        if re.search(SUBMISSION_DEADLINE_REGEX, sentence):
            if submission_deadline is None:
                submission_deadline = date_object
    return submission_deadline</code></pre>
</details>
</dd>
<dt id="extract.is_valid_file"><code class="name flex">
<span>def <span class="ident">is_valid_file</span></span>(<span>parser, arg)</span>
</code></dt>
<dd>
<section class="desc"><p>Given a file path, checks that the file exists.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>arg</code></strong></dt>
<dd>the path to the file</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>the file path as a string (if the file does exist)</dd>
<dt><strong><code>error</code></strong></dt>
<dd>an error (if the file does not exist)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_valid_file(parser, arg):
    &#34;&#34;&#34;
    Given a file path, checks that the file exists.
    Args:
        arg: the path to the file
    Returns:
          str: the file path as a string (if the file does exist)
          error: an error (if the file does not exist)
    &#34;&#34;&#34;
    if not os.path.isfile(arg):
        parser.error(&#34;ERROR: file %s does not exist.&#34; % arg) # if no file throw error
    else:
        return arg  # else return file path</code></pre>
</details>
</dd>
<dt id="extract.preprocess_text"><code class="name flex">
<span>def <span class="ident">preprocess_text</span></span>(<span>text)</span>
</code></dt>
<dd>
<section class="desc"><p>Method to preprocess text for information extraction. Text is split on newlines and commas,
and any conference names split over 2 lines are merged into one.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>split_cfp_text</code></strong></dt>
<dd>A list containing strings, where each string is a sentence in the original text.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>a list of preprocessed sentences.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_text(text):
    &#34;&#34;&#34;
    Method to preprocess text for information extraction. Text is split on newlines and commas,
    and any conference names split over 2 lines are merged into one.
    Args:
        split_cfp_text: A list containing strings, where each string is a sentence in the original text.
    Returns:
        list: a list of preprocessed sentences.
    &#34;&#34;&#34;

    text = text.replace(&#39;. &#39;, &#39;\n&#39;)
    text = text.splitlines()
    text = [substring for substring in text if substring is not &#34;&#34;]
    return text</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
    <li><code><a title="cfp_classifier" href="cfp_classifier.html">cfp_classifier</a></code></li>
    <li><code><a title="extract" href="extract.html">extract</a></code></li>
    <li><code><a title="evaluate" href="evaluate.html">evaluate</a></code></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="extract.extract_conference_name" href="#extract.extract_conference_name">extract_conference_name</a></code></li>
<li><code><a title="extract.extract_dates" href="#extract.extract_dates">extract_dates</a></code></li>
<li><code><a title="extract.extract_locations" href="#extract.extract_locations">extract_locations</a></code></li>
<li><code><a title="extract.get_final_version_deadline" href="#extract.get_final_version_deadline">get_final_version_deadline</a></code></li>
<li><code><a title="extract.get_notification_due" href="#extract.get_notification_due">get_notification_due</a></code></li>
<li><code><a title="extract.get_start_date" href="#extract.get_start_date">get_start_date</a></code></li>
<li><code><a title="extract.get_submission_deadline" href="#extract.get_submission_deadline">get_submission_deadline</a></code></li>
<li><code><a title="extract.is_valid_file" href="#extract.is_valid_file">is_valid_file</a></code></li>
<li><code><a title="extract.preprocess_text" href="#extract.preprocess_text">preprocess_text</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>